{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "a33744a8-08c7-4158-a22f-e8f2008a25b0",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "412b006d19b0209bd10ee4c6d15fdf59f8d2af38",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 0.23.0\n",
      "matplotlib version: 2.2.2\n",
      "NumPy version: 1.14.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD,Adam\n",
    "import keras.backend as K\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a514e15b-8caa-4b2e-bb46-13521761ef27",
    "_uuid": "2e4810f3c85ffdee7d7382167e455baf1c320bc8"
   },
   "source": [
    "# Load Data Modelling Libraries\n",
    "\n",
    "We will use the popular *scikit-learn* library to develop our machine learning algorithms. In *sklearn,* algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the *matplotlib* and *seaborn* library. Below are common classes to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b230c790-a3f5-46ed-b351-57e96cc8fa61",
    "_uuid": "4a16d09256317518769f21bf9cc38726df8b0078",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "# %matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data .... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#import data from file: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "#a dataset should be broken into 3 splits: train, test, and (final) validation\n",
    "#the test file provided is the validation file for competition submission\n",
    "#we will split the train set into train and test data in future sections\n",
    "df_test  = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "\n",
    "#however passing by reference is convenient, because we can clean both datasets at once\n",
    "data = pd.concat([df_train, df_test],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64 PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64 Age             263\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "Fare              1\n",
      "Name              0\n",
      "Parch             0\n",
      "PassengerId       0\n",
      "Pclass            0\n",
      "Sex               0\n",
      "SibSp             0\n",
      "Survived        418\n",
      "Ticket            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().sum(),df_test.isnull().sum(),data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding title column and digitizing Embarked, Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title categories added\n",
      "Embarked categories Digitized\n",
      "Pclass categories digitized\n"
     ]
    }
   ],
   "source": [
    "#quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "\n",
    "\n",
    "# Title bussiness\n",
    "data.loc[1305,\"Name\"] = \"Oliva y Ocana, Mrs. Dona. Fermina\" # Missing ttitle for Mrs Oliva\n",
    "data['Title'] = data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "\n",
    "# Fill age based on title\n",
    "for title in  data.groupby(['Title']).groups.keys():\n",
    "    age_to_impute = data.groupby('Title')['Age'].median()[title]\n",
    "    data.loc[(data['Age'].isnull()) & (data['Title'] == title), 'Age'] = age_to_impute\n",
    "\n",
    "# #Unify common titles. \n",
    "# data[\"Title\"] = data[\"Title\"].replace('Mlle', 'Miss')\n",
    "# data[\"Title\"] = data[\"Title\"].replace('Master', 'Master')\n",
    "# data[\"Title\"] = data[\"Title\"].replace(['Mme', 'Dona', 'Ms'], 'Mrs')\n",
    "# data[\"Title\"] = data[\"Title\"].replace(['Jonkheer','Don'],'Mr')\n",
    "# data[\"Title\"] = data[\"Title\"].replace(['Capt','Major', 'Col','Rev'], 'Millitary')\n",
    "# data[\"Title\"] = data[\"Title\"].replace(['Lady', 'the Countess', 'Countess','Sir'], 'Honor')\n",
    "\n",
    "# # convert Title categories to Columns\n",
    "# titledummies=pd.get_dummies(data[['Title']], prefix_sep='_') #Title\n",
    "# data = pd.concat([data, titledummies], axis=1) \n",
    "\n",
    "# print('Title categories added')\n",
    "\n",
    "# Repalcing titles by mean of surviving\n",
    "order_list = data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n",
    "title  = order_list.Title.values\n",
    "surv_mean = order_list.Survived.values\n",
    "title_mapping = dict(zip(title,surv_mean))\n",
    "data.loc[:,\"Title\"] = data[\"Title\"].map(title_mapping)\n",
    "print('Title categories added')\n",
    "\n",
    "\n",
    "# Repalcing Embarked by mean of surviving\n",
    "\n",
    "order_list = data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()\n",
    "title  = order_list.Embarked.values\n",
    "surv_mean = order_list.Survived.values\n",
    "title_mapping = dict(zip(title,surv_mean))\n",
    "data.loc[:,\"Embarked\"] = data[\"Embarked\"].map(title_mapping)\n",
    "data.loc[data['Embarked'].isnull()==True,\"Embarked\"] = data[\"Embarked\"].median()\n",
    "\n",
    "print('Embarked categories Digitized')\n",
    "\n",
    "# Sex digitalize\n",
    "data.loc[:,\"Sex\"] = data[\"Sex\"].replace(['male'], 1)\n",
    "data.loc[:,\"Sex\"] = data[\"Sex\"].replace(['female'], 0)\n",
    "\n",
    "#Discrete variables\n",
    "data['Family_Size'] = data ['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "data['IsAlone'] = 1 #initialize to yes/1 is alone\n",
    "data.loc[data['Family_Size'] > 1,\"IsAlone\"] = 0 # now update to no/b0 if family size is greater than 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Repalcing Pclass by mean of surviving\n",
    "order_list = data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()\n",
    "title  = order_list.Pclass.values\n",
    "surv_mean = order_list.Survived.values\n",
    "title_mapping = dict(zip(title,surv_mean))\n",
    "data.loc[:,\"Pclass\"] = data[\"Pclass\"].map(title_mapping)\n",
    "print('Pclass categories digitized')\n",
    "\n",
    "\n",
    "data.loc[data['Fare'].isnull()==True,\"Fare\"] = data[\"Fare\"].median()\n",
    "\n",
    "# # convert Pclass categories to Columns\n",
    "# titledummies =pd.get_dummies(data['Pclass'])\n",
    "# titledummies.rename(columns={1:'Pclass_1',2:'Pclass_2',3:'Pclass_3'}, inplace=True)\n",
    "# data = pd.concat([data, titledummies], axis=1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # data = data.drop([\"Cabin\",\"Name\",\"Ticket\",\"Title\"],axis =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Cabin          1014\n",
       "Embarked          0\n",
       "Fare              0\n",
       "Name              0\n",
       "Parch             0\n",
       "PassengerId       0\n",
       "Pclass            0\n",
       "Sex               0\n",
       "SibSp             0\n",
       "Survived        418\n",
       "Ticket            0\n",
       "Title             0\n",
       "Family_Size       0\n",
       "IsAlone           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding columns with missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family Survival\n",
    "\n",
    "This is based on code taken from from https://www.kaggle.com/shunjiangxu/blood-is-thicker-than-water-friendship-forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers with family survival information: 420\n",
      "Number of passenger with family/group survival information: 546\n"
     ]
    }
   ],
   "source": [
    "# get last name\n",
    "data[\"Last_Name\"] = data['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "# Set survival value\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data[\"Family_Survival\"] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "# Find Family groups by Fare\n",
    "for grp, grp_df in data[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "print(\"Number of passengers with family survival information:\", \n",
    "      data.loc[data['Family_Survival']!=0.5].shape[0])\n",
    "\n",
    "# Find Family groups by Ticket\n",
    "for _, grp_df in data.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0):\n",
    "                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                        \n",
    "print(\"Number of passenger with family/group survival information: \" \n",
    "      +str(data[data['Family_Survival']!=0.5].shape[0]))\n",
    "\n",
    "# # Family_Survival in df_train and df_test:\n",
    "# df_train[\"Family_Survival\"] = data['Family_Survival'][:891]\n",
    "# df_test[\"Family_Survival\"] = data['Family_Survival'][891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival expectation value by sex and pclass\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data[\"Sx_Pa_Survival\"] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "df_train = data[:891]\n",
    "\n",
    "list_groups = df_train.groupby([\"Parch\",\"Sex\"])[\"Sx_Pa_Survival\"].count().values\n",
    "\n",
    "\n",
    "surv_list_groups = df_train.groupby([\"Parch\",\"Sex\",\"Survived\"])[\"Sx_Pa_Survival\"].count().values\n",
    "\n",
    "\n",
    "surv = surv_list_groups[1:14:2]\n",
    "\n",
    "surv_rate1 = surv/list_groups[:7]\n",
    "\n",
    "\n",
    "\n",
    "for grp in data.groupby([\"Parch\",\"Sex\"]): \n",
    "#     print(grp[0])\n",
    "    if grp[0] == (1,0):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = surv_rate1[0]\n",
    "    if grp[0] == (0,1):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = surv_rate1[1]\n",
    "    if grp[0] == (1,0):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = surv_rate1[2]\n",
    "    if grp[0] == (1,1):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = surv_rate1[3]\n",
    "    if grp[0] == (2,0):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = surv_rate1[4]\n",
    "    if grp[0] == (2,1):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = surv_rate1[5]  \n",
    "    if grp[0] == (3,0):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = surv_rate1[6] \n",
    "    if grp[0] == (3,1):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = 0\n",
    "    if grp[0] == (4,0):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = 0\n",
    "    if grp[0] == (4,1):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = 0    \n",
    "    if grp[0] == (5,0):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = .25\n",
    "    if grp[0] == (5,1):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = 0\n",
    "    if grp[0] == (6,0):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = 0\n",
    "    if grp[0] == (6,1):  data.loc[grp[1].index.values,[\"Sx_Pa_Survival\"]] = .5\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival expectation value by sex and pclass\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data[\"Sx_Si_Survival\"] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "df_train = data[:891]\n",
    "\n",
    "list_groups = df_train.groupby([\"SibSp\",\"Sex\"])[\"Sx_Si_Survival\"].count().values\n",
    "\n",
    "\n",
    "\n",
    "surv_list_groups = df_train.groupby([\"SibSp\",\"Sex\",\"Survived\"])[\"Sx_Pa_Survival\"].count().values\n",
    "\n",
    "\n",
    "\n",
    "surv = surv_list_groups[14::2]\n",
    "\n",
    "\n",
    "for grp in data.groupby([\"SibSp\",\"Sex\"]): \n",
    "#     print(grp[0])\n",
    "    if grp[0] == (1,0):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = surv_rate1[0]\n",
    "    if grp[0] == (0,1):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = surv_rate1[1]\n",
    "    if grp[0] == (1,0):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = surv_rate1[2]\n",
    "    if grp[0] == (1,1):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = surv_rate1[3]\n",
    "    if grp[0] == (2,0):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = surv_rate1[4]\n",
    "    if grp[0] == (2,1):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = surv_rate1[5]  \n",
    "    if grp[0] == (3,0):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = surv_rate1[6] \n",
    "    if grp[0] == (3,1):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = 0\n",
    "    if grp[0] == (4,0):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] =       2/6\n",
    "    if grp[0] == (4,1):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] =    1/12\n",
    "    if grp[0] == (5,0):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = 0\n",
    "    if grp[0] == (5,1):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = 0\n",
    "    if grp[0] == (8,0):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = .5\n",
    "    if grp[0] == (8,1):  data.loc[grp[1].index.values,[\"Sx_Si_Survival\"]] = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUMERIC_COLUMNS=['Alone','Family Size','Sex','Pclass','Fare','FareBand','Age','TitleCat','Embarked'] #72\n",
    "ORIGINAL_NUMERIC_COLUMNS=['Pclass','Age','SibSp','Parch','Sex','Title_Master', 'Title_Miss','Title_Mr', 'Title_Mrs', 'Title_Millitary','Embarked'] #83\n",
    "REVISED_NUMERIC_COLUMNS=[ 'Fare','Sex','Pclass','Age','Parch','Title','IsAlone','Embarked','Family_Size'] #84\n",
    "# 'Sx_Cl_Survival','Sx_Em_Survival',\"Sx_Si_Survival\",\"Sx_Pa_Survival\",'Title_Dr','Title_Master', 'Title_Miss','Title_Mr', 'Title_Mrs', 'Title_Millitary',\n",
    "#'Family_Size', \n",
    "\n",
    "data[REVISED_NUMERIC_COLUMNS] = data[REVISED_NUMERIC_COLUMNS].values / np.max(data[REVISED_NUMERIC_COLUMNS].values,axis=0)\n",
    "# data[REVISED_NUMERIC_COLUMNS] = normalize(data[REVISED_NUMERIC_COLUMNS].values)\n",
    "# for x in REVISED_NUMERIC_COLUMNS:\n",
    "#     data[x] = data[x]/np.max(data[x].values)\n",
    "\n",
    "\n",
    "#'\n",
    "df_train = data[:891]\n",
    "df_test = data[891:]\n",
    "\n",
    "\n",
    "# create test and training data\n",
    "data_to_train = df_train[REVISED_NUMERIC_COLUMNS].fillna(-1000)\n",
    "y=df_train['Survived'].values\n",
    "X=data_to_train.values\n",
    "X_train, X_test, Y_train, Y_test =  model_selection.train_test_split(X, y, test_size=0.3,random_state=1, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Family_Survival</th>\n",
       "      <th>Sx_Cl_Survival</th>\n",
       "      <th>Sx_Pa_Survival</th>\n",
       "      <th>Sx_Si_Survival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.384929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0.156673</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Braund</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>0.327586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4750</td>\n",
       "      <td>C85</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.384929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>0.697802</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>C123</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.384929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>0.156673</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>0.165289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Cabin  Embarked      Fare  \\\n",
       "0  0.2750   NaN  0.608696  0.014151   \n",
       "1  0.4750   C85  1.000000  0.139136   \n",
       "2  0.3250   NaN  0.608696  0.015469   \n",
       "3  0.4375  C123  0.608696  0.103644   \n",
       "4  0.4375   NaN  0.608696  0.015713   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris    0.0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0.0            2   \n",
       "2                             Heikkinen, Miss. Laina    0.0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0.0            4   \n",
       "4                           Allen, Mr. William Henry    0.0            5   \n",
       "\n",
       "     Pclass  Sex  SibSp  Survived            Ticket     Title  Family_Size  \\\n",
       "0  0.384929  1.0      1       0.0         A/5 21171  0.156673     0.181818   \n",
       "1  1.000000  0.0      1       1.0          PC 17599  0.792000     0.181818   \n",
       "2  0.384929  0.0      0       1.0  STON/O2. 3101282  0.697802     0.090909   \n",
       "3  1.000000  0.0      1       1.0            113803  0.792000     0.181818   \n",
       "4  0.384929  1.0      0       0.0            373450  0.156673     0.090909   \n",
       "\n",
       "   IsAlone  Last_Name  Family_Survival  Sx_Cl_Survival  Sx_Pa_Survival  \\\n",
       "0      0.0     Braund              0.5             0.5        0.165289   \n",
       "1      0.0    Cumings              0.5             0.5        0.500000   \n",
       "2      1.0  Heikkinen              0.5             0.5        0.500000   \n",
       "3      0.0   Futrelle              0.0             0.5        0.500000   \n",
       "4      1.0      Allen              0.5             0.5        0.165289   \n",
       "\n",
       "   Sx_Si_Survival  \n",
       "0        0.327586  \n",
       "1        0.766667  \n",
       "2        0.500000  \n",
       "3        0.766667  \n",
       "4        0.165289  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train_new.csv\")\n",
    "df_test.to_csv(\"test_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
